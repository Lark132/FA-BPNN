import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense, LeakyReLU
from keras.initializers import RandomNormal
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
from sklearn.model_selection import train_test_split
import joblib

# ==== 1. 配置参数 ====
features = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11']
y_labels = ['yield_dis', 'yield_load', 'peak_dis', 'peak_load', 'ultimate_dis']
data_path = 'data.xlsx'

# ==== 2. 读取数据并划分训练集和测试集 ====
data_df = pd.read_excel(data_path, header=None, names=features + y_labels, engine='openpyxl')

X = data_df[features].values
y = data_df[y_labels].values

# 测试集占20%，训练集占80%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)

# ==== 3. 数据归一化 ====
scaler_X = MinMaxScaler()
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

scaler_y = MinMaxScaler()
y_train_scaled = scaler_y.fit_transform(y_train)
y_test_scaled = scaler_y.transform(y_test)

# ==== 4. 构建 BPNN 模型（全 LeakyReLU） ====
model = Sequential()
model.add(Dense(17, input_dim=11, kernel_initializer=RandomNormal()))
model.add(LeakyReLU(alpha=0.01))

model.add(Dense(15, kernel_initializer=RandomNormal()))
model.add(LeakyReLU(alpha=0.01))

model.add(Dense(5, kernel_initializer=RandomNormal()))
model.add(LeakyReLU(alpha=0.01))

model.compile(optimizer=Adam(learning_rate=0.01),
              loss='mean_squared_error',
              metrics=['mean_absolute_error'])

# ==== 5. 模型训练 ====
model.fit(X_train_scaled, y_train_scaled, epochs=300, batch_size=30, verbose=1)

# ==== 6. 保存模型和归一化器 ====
model.save('trained_bpnn_model_leakyrelu.h5')
joblib.dump(scaler_X, 'scaler_X.save')
joblib.dump(scaler_y, 'scaler_y.save')
print("✅ 模型和归一化器已保存。")

# ==== 7. 模型预测并反归一化 ====
y_train_pred_scaled = model.predict(X_train_scaled)
y_test_pred_scaled = model.predict(X_test_scaled)

y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled)
y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)
y_train_true = scaler_y.inverse_transform(y_train_scaled)
y_test_true = scaler_y.inverse_transform(y_test_scaled)

# ==== 8. 评估函数 ====
def evaluate(y_true, y_pred, labels):
    mae = [mean_absolute_error(y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])]
    mse = [mean_squared_error(y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])]
    rmse = [np.sqrt(m) for m in mse]
    r2 = [r2_score(y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])]
    mape = [mean_absolute_percentage_error(y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])]

    df = pd.DataFrame({
        '输出变量': labels,
        'MAE': mae,
        'RMSE': rmse,
        'R2': r2,
        'MAPE': mape
    })
    return df

# ==== 9. 计算并打印训练集误差指标 ====
train_metrics = evaluate(y_train_true, y_train_pred, y_labels)

print("\n======================== 训练集误差指标（反归一化后） ========================")
print(train_metrics.to_string(index=False))